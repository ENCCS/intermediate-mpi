<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Non-blocking point-to-point &mdash; Intermediate MPI</title>
      <link rel="stylesheet" href="../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
      <link rel="stylesheet" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" type="text/css" />
      <link rel="stylesheet" href="../_static/copybutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/togglebutton.css" type="text/css" />
      <link rel="stylesheet" href="../_static/sphinx_lesson.css" type="text/css" />
      <link rel="stylesheet" href="../_static/overrides.css" type="text/css" />
      <link rel="stylesheet" href="../_static/tabs.css" type="text/css" />
    <link rel="shortcut icon" href="../_static/favicon.ico"/>
  <!--[if lt IE 9]>
    <script src="../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
        <script src="../_static/jquery.js"></script>
        <script src="../_static/underscore.js"></script>
        <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../_static/doctools.js"></script>
        <script src="../_static/sphinx_highlight.js"></script>
        <script src="../_static/clipboard.min.js"></script>
        <script src="../_static/copybutton.js"></script>
        <script src="../_static/minipres.js"></script>
        <script>let toggleHintShow = 'Click to show';</script>
        <script>let toggleHintHide = 'Click to hide';</script>
        <script>let toggleOpenOnPrint = 'true';</script>
        <script src="../_static/togglebutton.js"></script>
        <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
        <script data-domain="enccs.github.io/intermediate-mpi" defer="defer" src="https://plausible.io/js/script.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex/" />
    <link rel="search" title="Search" href="../search/" />
    <link rel="next" title="Non-blocking collective communication" href="../non-blocking-communication-pt2/" />
    <link rel="prev" title="Generalized forms of gather" href="../collective-communication-pt3/" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../" class="icon icon-home">
            Intermediate MPI
              <img src="../_static/ENCCS.jpg" class="logo" alt="Logo"/>
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search/" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../setup/">Setting up your system</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">The lesson</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="../communicators-groups/">Communicators and groups</a></li>
<li class="toctree-l1"><a class="reference internal" href="../derived-datatypes-pt1/">Derived datatypes: pack and unpack</a></li>
<li class="toctree-l1"><a class="reference internal" href="../derived-datatypes-pt2/">Derived datatypes: <code class="docutils literal notranslate"><span class="pre">MPI_Datatype</span></code></a></li>
<li class="toctree-l1"><a class="reference internal" href="../collective-communication-pt1/">Simple collective communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../collective-communication-pt2/">Scatter and gather</a></li>
<li class="toctree-l1"><a class="reference internal" href="../collective-communication-pt3/">Generalized forms of gather</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Non-blocking point-to-point</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#introduction">Introduction</a></li>
<li class="toctree-l2"><a class="reference internal" href="#stencil-application-example">Stencil application example</a></li>
<li class="toctree-l2"><a class="reference internal" href="#non-performant-mpi-workflows-for-stencil-applications-blocking-messages">Non-performant MPI workflows for stencil applications: blocking messages</a></li>
<li class="toctree-l2"><a class="reference internal" href="#performant-mpi-workflows-for-stencil-applications-non-blocking-messages">Performant MPI workflows for stencil applications: non-blocking messages</a></li>
<li class="toctree-l2"><a class="reference internal" href="#non-blocking-mpi-send-calls">Non-blocking MPI send calls</a></li>
<li class="toctree-l2"><a class="reference internal" href="#non-blocking-mpi-receive-call">Non-blocking MPI receive call</a></li>
<li class="toctree-l2"><a class="reference internal" href="#waiting-for-non-blocking-call-completion">Waiting for non-blocking call completion</a></li>
<li class="toctree-l2"><a class="reference internal" href="#testing-for-non-blocking-call-completion">Testing for non-blocking call completion</a></li>
<li class="toctree-l2"><a class="reference internal" href="#see-also">See also</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../non-blocking-communication-pt2/">Non-blocking collective communication</a></li>
<li class="toctree-l1"><a class="reference internal" href="../one-sided-concepts/">One-sided communication: concepts</a></li>
<li class="toctree-l1"><a class="reference internal" href="../one-sided-routines/">One-sided communication: functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="../one-sided-sync/">One-sided communication: synchronization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mpi-and-threads-pt1/">Introducing MPI and threads</a></li>
<li class="toctree-l1"><a class="reference internal" href="../mpi-and-threads-pt2/">MPI and threads in practice</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Reference</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../quick-reference/">Quick Reference</a></li>
<li class="toctree-l1"><a class="reference internal" href="../zbibliography/">Bibliography</a></li>
<li class="toctree-l1"><a class="reference internal" href="../guide/">Instructor’s guide</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../">Intermediate MPI</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Non-blocking point-to-point</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/ENCCS/intermediate-mpi/blob/master/content/non-blocking-communication-pt1.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="non-blocking-point-to-point">
<h1>Non-blocking point-to-point<a class="headerlink" href="#non-blocking-point-to-point" title="Permalink to this heading"></a></h1>
<div class="admonition-questions questions admonition" id="questions-0">
<p class="admonition-title">Questions</p>
<ul class="simple">
<li><p>Does blocking communication scale well?</p></li>
<li><p>Can my code do useful work while waiting for messages?</p></li>
</ul>
</div>
<div class="admonition-objectives objectives admonition" id="objectives-0">
<p class="admonition-title">Objectives</p>
<ul class="simple">
<li><p>Understand that messages can lead to deadlocks</p></li>
<li><p>Using non-blocking point-to-point messages in a stencil halo exchange application</p></li>
</ul>
</div>
<section id="introduction">
<h2>Introduction<a class="headerlink" href="#introduction" title="Permalink to this heading"></a></h2>
<p>Communication operations take time to happen. Most of that time
doesn’t need the CPU to participate, particularly if the network
hardware is good. Many applications have work to do on the data they
already have available in the local process, and then work to do on
data that arrives in a message. Likewise, they often need to have sent
data for other processes to use later.</p>
<p>These messages can be sent synchronously using the point-to-point
message types we already learned about. However the synchronization
takes time, and this limits how far one can parallelise.</p>
</section>
<section id="stencil-application-example">
<h2>Stencil application example<a class="headerlink" href="#stencil-application-example" title="Permalink to this heading"></a></h2>
<p>Stencils are a kind of computational kernel often used in PDE solvers.
A simple example is a diffusive heat-flow model, where the amount of
heat in a location at the next point in time depends on the amount of
heat currently present there, and the amounts in the nearest neighbour
locations.</p>
<figure class="align-center" id="id2">
<img alt="../_images/StencilApplication.svg" src="../_images/StencilApplication.svg" /><figcaption>
<p><span class="caption-text">The model of the problem uses an 8x8 grid of data in light blue,
which has to be updated based on the indicated 5-point stencil in
light green to move from one time point to another.</span><a class="headerlink" href="#id2" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>Let us assume the grid is periodic, ie. the left-hand edge is adjacent
to the right-hand edge (like the video game Space Invaders!), and
likewise top and bottom. Such a grid models a torus. In order to
update the amount of heat at every location, all the amount of heat at
all four of its neighbours must also be known locally. That’s
straightforward when using a single process, because everything is
local. But what happens when using two ranks?</p>
<figure class="align-center" id="id3">
<img alt="../_images/HaloExchange.svg" src="../_images/HaloExchange.svg" /><figcaption>
<p><span class="caption-text">The two processes share the data evenly, in a 4x8 local data set
shown in light blue.  In order to compute the heat at the next time
step, the required data set is larger than this, shown in yellow.</span><a class="headerlink" href="#id3" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>The required data to the left and right of the local data set is easy,
because that data is already present locally, just on the other side
of the local data set. However the top and bottom yellow data has to
come from the other process.</p>
<figure class="align-center" id="id4">
<img alt="../_images/Workingdatasets.svg" src="../_images/Workingdatasets.svg" /><figcaption>
<p><span class="caption-text">The <code class="docutils literal notranslate"><span class="pre">border</span> <span class="pre">data</span></code> in dark blue has to be sent to the other
process, and the <code class="docutils literal notranslate"><span class="pre">ghost</span> <span class="pre">data</span></code> or <code class="docutils literal notranslate"><span class="pre">halo</span> <span class="pre">data</span></code> in dark green is
received from the other process.</span><a class="headerlink" href="#id4" title="Permalink to this image"></a></p>
</figcaption>
</figure>
</section>
<section id="non-performant-mpi-workflows-for-stencil-applications-blocking-messages">
<h2>Non-performant MPI workflows for stencil applications: blocking messages<a class="headerlink" href="#non-performant-mpi-workflows-for-stencil-applications-blocking-messages" title="Permalink to this heading"></a></h2>
<p>A possible workflow for the code on these two processes looks like</p>
<figure class="align-center" id="id5">
<img alt="../_images/simplestencilworkflow.svg" src="../_images/simplestencilworkflow.svg" /><figcaption>
<p><span class="caption-text">A simple parallel stencil-computation workflow. Depending on the
MPI implementation, doing the send first on both ranks can lead to
a deadlock.</span><a class="headerlink" href="#id5" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>This may work sometimes, but it also might not if the buffers or
number of messages gets large enough. Such code will not be
portable.</p>
<figure class="align-center" id="id6">
<img alt="../_images/ring-stylestencilworkflow.svg" src="../_images/ring-stylestencilworkflow.svg" /><figcaption>
<p><span class="caption-text">A correct ring-style parallel stencil-computation workflow.</span><a class="headerlink" href="#id6" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>This workflow will always work. This approach generalizes to larger
rings, so long as alternating processes either send or respectively
receive first. It also generalizes to multiple dimensions. However, it
still requires synchronization between send and receive ranks. That
synchronization is problematic when the time to send messages is
comparable with either the amounts of compute work involved, or the
variation in those amounts.</p>
</section>
<section id="performant-mpi-workflows-for-stencil-applications-non-blocking-messages">
<h2>Performant MPI workflows for stencil applications: non-blocking messages<a class="headerlink" href="#performant-mpi-workflows-for-stencil-applications-non-blocking-messages" title="Permalink to this heading"></a></h2>
<figure class="align-center" id="id7">
<img alt="../_images/non-blocking-stylestencilworkflow.svg" src="../_images/non-blocking-stylestencilworkflow.svg" /><figcaption>
<p><span class="caption-text">A correct non-blocking-style parallel stencil-computation
workflow. The MPI implementation may be able to do the
communication overlapped with the computation.</span><a class="headerlink" href="#id7" title="Permalink to this image"></a></p>
</figcaption>
</figure>
<p>This will also always work. It may be more efficient than the
ring-style approach, but that depends on the implementation and
environment, as well as the size of messages and amounts of compute
that can participate in the overlapped region.</p>
<p>The user is responsible for not using the memory area until after the
message request has been waited upon.</p>
</section>
<section id="non-blocking-mpi-send-calls">
<h2>Non-blocking MPI send calls<a class="headerlink" href="#non-blocking-mpi-send-calls" title="Permalink to this heading"></a></h2>
<p>An <a class="reference internal" href="../quick-reference/index.html#term-MPI_Isend"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Isend</code></span></a> creates a send request and returns a request
object. It may or may not have sent the message, or buffered it. The
caller is responsible for not changing the buffer until after waiting
upon the resulting request object.</p>
<div class="admonition-term-mpi-isend signature toggle-shown dropdown admonition" id="signature-0">
<p class="admonition-title"><a class="reference internal" href="../quick-reference/index.html#term-MPI_Isend"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Isend</code></span></a></p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="n">MPI_Isend</span><span class="p">(</span><span class="k">const</span><span class="w"> </span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">buf</span><span class="p">,</span>
<span class="w">              </span><span class="kt">int</span><span class="w"> </span><span class="n">count</span><span class="p">,</span>
<span class="w">              </span><span class="n">MPI_Datatype</span><span class="w"> </span><span class="n">datatype</span><span class="p">,</span>
<span class="w">              </span><span class="kt">int</span><span class="w"> </span><span class="n">dest</span><span class="p">,</span>
<span class="w">              </span><span class="kt">int</span><span class="w"> </span><span class="n">tag</span><span class="p">,</span>
<span class="w">              </span><span class="n">MPI_Comm</span><span class="w"> </span><span class="n">comm</span><span class="p">,</span>
<span class="w">              </span><span class="n">MPI_Request</span><span class="w"> </span><span class="o">*</span><span class="n">request</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition-parameters parameters dropdown admonition" id="parameters-0">
<p class="admonition-title">Parameters</p>
<p><code class="docutils literal notranslate"><span class="pre">buf</span></code>, <code class="docutils literal notranslate"><span class="pre">count</span></code> and <code class="docutils literal notranslate"><span class="pre">datatype</span></code> describe the buffer to be sent
to <code class="docutils literal notranslate"><span class="pre">dest</span></code> rank of <code class="docutils literal notranslate"><span class="pre">comm</span></code> using tag <code class="docutils literal notranslate"><span class="pre">tag</span></code>. The <code class="docutils literal notranslate"><span class="pre">request</span></code> object
that is returned must be used to wait on the communication later.</p>
</div>
<p>Other calls exist for other sending modes familiar to you from
point-to-point messages, including buffered, synchronous, and
ready-mode sends. They are listed in the table below, along with
links for more information.</p>
<table class="docutils align-default" id="id8">
<caption><span class="caption-text">Point-to-point communication functions</span><a class="headerlink" href="#id8" title="Permalink to this table"></a></caption>
<thead>
<tr class="row-odd"><th class="head" colspan="2" rowspan="2"></th>
<th class="head" colspan="2"><p>Communication</p></th>
</tr>
<tr class="row-even"><th class="head"><p>Blocking</p></th>
<th class="head"><p>Non-blocking</p></th>
</tr>
</thead>
<tbody>
<tr class="row-odd"><td rowspan="4"><p><strong>Mode</strong></p></td>
<td><p><strong>Standard</strong></p></td>
<td><p><a class="reference internal" href="../quick-reference/index.html#term-MPI_Send"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Send</code></span></a></p></td>
<td><p><a class="reference internal" href="../quick-reference/index.html#term-MPI_Isend"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Isend</code></span></a></p></td>
</tr>
<tr class="row-even"><td><p><strong>Synchronous</strong></p></td>
<td><p><a class="reference internal" href="../quick-reference/index.html#term-MPI_Ssend"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Ssend</code></span></a></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">MPI_Issend</span></code></p></td>
</tr>
<tr class="row-odd"><td><p><strong>Ready</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">MPI_Rsend</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">MPI_Irsend</span></code></p></td>
</tr>
<tr class="row-even"><td><p><strong>Buffered</strong></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">MPI_Bsend</span></code></p></td>
<td><p><code class="docutils literal notranslate"><span class="pre">MPI_Ibsend</span></code></p></td>
</tr>
</tbody>
</table>
</section>
<section id="non-blocking-mpi-receive-call">
<h2>Non-blocking MPI receive call<a class="headerlink" href="#non-blocking-mpi-receive-call" title="Permalink to this heading"></a></h2>
<p>An <a class="reference internal" href="../quick-reference/index.html#term-MPI_Irecv"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Irecv</code></span></a> creates a receive request and returns a receive
request in an <code class="docutils literal notranslate"><span class="pre">MPI_Request</span></code> object. The caller is responsible for
not changing the buffer until after waiting upon the resulting request
object.</p>
<div class="admonition-term-mpi-irecv signature toggle-shown dropdown admonition" id="signature-1">
<p class="admonition-title"><a class="reference internal" href="../quick-reference/index.html#term-MPI_Irecv"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Irecv</code></span></a></p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="n">MPI_Irecv</span><span class="p">(</span><span class="kt">void</span><span class="o">*</span><span class="w"> </span><span class="n">buf</span><span class="p">,</span>
<span class="w">              </span><span class="kt">int</span><span class="w"> </span><span class="n">count</span><span class="p">,</span>
<span class="w">              </span><span class="n">MPI_Datatype</span><span class="w"> </span><span class="n">datatype</span><span class="p">,</span>
<span class="w">              </span><span class="kt">int</span><span class="w"> </span><span class="n">source</span><span class="p">,</span>
<span class="w">              </span><span class="kt">int</span><span class="w"> </span><span class="n">tag</span><span class="p">,</span>
<span class="w">              </span><span class="n">MPI_Comm</span><span class="w"> </span><span class="n">comm</span><span class="p">,</span>
<span class="w">              </span><span class="n">MPI_Request</span><span class="w"> </span><span class="o">*</span><span class="n">request</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition-parameters parameters dropdown admonition" id="parameters-1">
<p class="admonition-title">Parameters</p>
<p><code class="docutils literal notranslate"><span class="pre">buf</span></code>, <code class="docutils literal notranslate"><span class="pre">count</span></code> and <code class="docutils literal notranslate"><span class="pre">datatype</span></code> describe the buffer to be
received from <code class="docutils literal notranslate"><span class="pre">source</span></code> rank of <code class="docutils literal notranslate"><span class="pre">comm</span></code> using tag <code class="docutils literal notranslate"><span class="pre">tag</span></code>. The
<code class="docutils literal notranslate"><span class="pre">request</span></code> object that is returned must be used to wait on the
communication later.</p>
</div>
<p>An <a class="reference internal" href="../quick-reference/index.html#term-MPI_Irecv"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Irecv</code></span></a> can be used to match any kind of send, regardless of
sending mode or blocking status.</p>
</section>
<section id="waiting-for-non-blocking-call-completion">
<h2>Waiting for non-blocking call completion<a class="headerlink" href="#waiting-for-non-blocking-call-completion" title="Permalink to this heading"></a></h2>
<p>An <a class="reference internal" href="../quick-reference/index.html#term-MPI_Wait"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Wait</code></span></a> call waits for completion of the operation that
created the request object passed to it. For a send, the semantics of
the sending mode have been fulfilled (not necessarily that the message
has been received). For a receive, the buffer is now valid for use,
however the send has not necessarily completed (though obviously has
been initiated).</p>
<div class="admonition-term-mpi-wait signature toggle-shown dropdown admonition" id="signature-2">
<p class="admonition-title"><a class="reference internal" href="../quick-reference/index.html#term-MPI_Wait"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Wait</code></span></a></p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="n">MPI_Wait</span><span class="p">(</span><span class="n">MPI_Request</span><span class="w"> </span><span class="o">*</span><span class="n">request</span><span class="p">,</span>
<span class="w">             </span><span class="n">MPI_Status</span><span class="w"> </span><span class="o">*</span><span class="n">status</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition-parameters parameters dropdown admonition" id="parameters-2">
<p class="admonition-title">Parameters</p>
<p><code class="docutils literal notranslate"><span class="pre">request</span></code> describes the operation to be waited upon. <code class="docutils literal notranslate"><span class="pre">status</span></code>
returns the status of that operation. If the status is not needed,
pass <code class="docutils literal notranslate"><span class="pre">MPI_STATUS_IGNORE</span></code>.</p>
</div>
<p>It can be efficient to wait on any one, some, or all of a set of
operations before returning. MPI provides <a class="reference internal" href="../quick-reference/index.html#term-MPI_Waitany"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Waitany</code></span></a>,
<a class="reference internal" href="../quick-reference/index.html#term-MPI_Waitsome"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Waitsome</code></span></a>, and <a class="reference internal" href="../quick-reference/index.html#term-MPI_Waitall"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Waitall</code></span></a> for these use cases. For example,
waiting for any request to complete may allow the caller to continue
with related computation while waiting for other requests to complete.</p>
</section>
<section id="testing-for-non-blocking-call-completion">
<h2>Testing for non-blocking call completion<a class="headerlink" href="#testing-for-non-blocking-call-completion" title="Permalink to this heading"></a></h2>
<p>An <a class="reference internal" href="../quick-reference/index.html#term-MPI_Test"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Test</code></span></a> call returns immediately a flag value indicating
whether a corresponding <a class="reference internal" href="../quick-reference/index.html#term-MPI_Wait"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Wait</code></span></a> would return immediately.</p>
<div class="admonition-term-mpi-test signature toggle-shown dropdown admonition" id="signature-3">
<p class="admonition-title"><a class="reference internal" href="../quick-reference/index.html#term-MPI_Test"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Test</code></span></a></p>
<div class="highlight-c notranslate"><div class="highlight"><pre><span></span><span class="kt">int</span><span class="w"> </span><span class="n">MPI_Test</span><span class="p">(</span><span class="n">MPI_Request</span><span class="w"> </span><span class="o">*</span><span class="n">request</span><span class="p">,</span><span class="w"> </span><span class="kt">int</span><span class="w"> </span><span class="o">*</span><span class="n">flag</span><span class="p">,</span><span class="w"> </span><span class="n">MPI_Status</span><span class="w"> </span><span class="o">*</span><span class="n">status</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition-parameters parameters dropdown admonition" id="parameters-3">
<p class="admonition-title">Parameters</p>
<p><code class="docutils literal notranslate"><span class="pre">request</span></code> describes the operation to be waited upon. <code class="docutils literal notranslate"><span class="pre">status</span></code>
returns the status of that operation. If the status is not needed,
pass <code class="docutils literal notranslate"><span class="pre">MPI_STATUS_IGNORE</span></code>. The value returned in <code class="docutils literal notranslate"><span class="pre">flag</span></code> indicates
whether the operation is complete (ie a corresponding wait will
return immediately).</p>
</div>
<p>It can be efficient to test any one, some, or all of a set of
operations before returning. MPI provides <a class="reference internal" href="../quick-reference/index.html#term-MPI_Testany"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Testany</code></span></a>,
<a class="reference internal" href="../quick-reference/index.html#term-MPI_Testsome"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Testsome</code></span></a>, and <a class="reference internal" href="../quick-reference/index.html#term-MPI_Testall"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Testall</code></span></a> for these use cases. For
example, testing for any request completed may allow the caller to
continue with unrelated computation because no message with work has
yet arrived.</p>
<div class="admonition-observe-a-deadlock-in-a-non-blocking-stencil-application exercise important admonition" id="exercise-0">
<p class="admonition-title">Observe a deadlock in a non-blocking stencil application</p>
<p>You can find a scaffold for the code in the
<code class="docutils literal notranslate"><span class="pre">content/code/day-2/04_deadlock</span></code> folder.  A working solution is in the
<code class="docutils literal notranslate"><span class="pre">solution</span></code> subfolder. Try to compile with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mpicc</span> <span class="o">-</span><span class="n">g</span> <span class="o">-</span><span class="n">Wall</span> <span class="o">-</span><span class="n">std</span><span class="o">=</span><span class="n">c11</span> <span class="n">non</span><span class="o">-</span><span class="n">blocking</span><span class="o">-</span><span class="n">communication</span><span class="o">-</span><span class="n">deadlock</span><span class="o">.</span><span class="n">c</span> <span class="o">-</span><span class="n">o</span> <span class="n">non</span><span class="o">-</span><span class="n">blocking</span><span class="o">-</span><span class="n">communication</span><span class="o">-</span><span class="n">deadlock</span>
</pre></div>
</div>
<ol class="arabic">
<li><p>When you have the code compiling, try to run with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mpiexec</span> <span class="o">-</span><span class="n">np</span> <span class="mi">2</span> <span class="o">./</span><span class="n">non</span><span class="o">-</span><span class="n">blocking</span><span class="o">-</span><span class="n">communication</span><span class="o">-</span><span class="n">deadlock</span>
</pre></div>
</div>
</li>
<li><p>The communication may block. If it does, you will have to kill
the process to continue, e.g. with <code class="docutils literal notranslate"><span class="pre">Ctrl-C</span></code>. If it doesn’t,
follow the first challenge to use a call to <a class="reference internal" href="../quick-reference/index.html#term-MPI_Ssend"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Ssend</code></span></a>
to make it block.</p></li>
<li><p>Try to fix the code so that one process sends before receiving
and the other process does the opposite. Now it will work even
if the runtime chooses to implement <a class="reference internal" href="../quick-reference/index.html#term-MPI_Send"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Send</code></span></a> like
<a class="reference internal" href="../quick-reference/index.html#term-MPI_Ssend"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Ssend</code></span></a>.</p></li>
</ol>
</div>
<div class="admonition-solution solution important dropdown admonition" id="solution-0">
<p class="admonition-title">Solution</p>
<ul>
<li><p>One correct approach is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">/*</span> <span class="n">Do</span> <span class="n">sends</span> <span class="ow">and</span> <span class="n">receives</span> <span class="ow">in</span> <span class="n">the</span> <span class="n">opposite</span> <span class="n">order</span> <span class="n">on</span> <span class="n">the</span> <span class="n">two</span> <span class="n">ranks</span> <span class="o">*/</span>
<span class="k">if</span> <span class="p">(</span><span class="n">rank</span> <span class="o">==</span> <span class="mi">0</span><span class="p">)</span>
<span class="p">{</span>
    <span class="nb">int</span> <span class="n">send_up_tag</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">send_down_tag</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="o">/*</span> <span class="n">Send</span> <span class="n">the</span> <span class="n">border</span> <span class="n">data</span> <span class="o">*/</span>
    <span class="nb">int</span> <span class="n">destination_rank</span> <span class="o">=</span> <span class="n">size</span><span class="o">-</span><span class="n">rank</span><span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="n">MPI_Ssend</span><span class="p">(</span><span class="n">working_data_set</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">8</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">destination_rank</span><span class="p">,</span> <span class="n">send_up_tag</span><span class="p">,</span> <span class="n">comm</span><span class="p">);</span>
    <span class="n">MPI_Ssend</span><span class="p">(</span><span class="n">working_data_set</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="mi">8</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">destination_rank</span><span class="p">,</span> <span class="n">send_down_tag</span><span class="p">,</span> <span class="n">comm</span><span class="p">);</span>

    <span class="o">/*</span> <span class="n">Receive</span> <span class="n">the</span> <span class="n">halo</span> <span class="n">data</span> <span class="o">*/</span>
    <span class="nb">int</span> <span class="n">source_rank</span> <span class="o">=</span> <span class="n">size</span><span class="o">-</span><span class="n">rank</span><span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="n">MPI_Recv</span><span class="p">(</span><span class="n">working_data_set</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="mi">8</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">source_rank</span><span class="p">,</span> <span class="n">send_up_tag</span><span class="p">,</span> <span class="n">comm</span><span class="p">,</span> <span class="n">MPI_STATUS_IGNORE</span><span class="p">);</span>
    <span class="n">MPI_Recv</span><span class="p">(</span><span class="n">working_data_set</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">8</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">source_rank</span><span class="p">,</span> <span class="n">send_down_tag</span><span class="p">,</span> <span class="n">comm</span><span class="p">,</span> <span class="n">MPI_STATUS_IGNORE</span><span class="p">);</span>
<span class="p">}</span>
<span class="k">else</span>
<span class="p">{</span>
    <span class="nb">int</span> <span class="n">send_up_tag</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="n">send_down_tag</span> <span class="o">=</span> <span class="mi">1</span><span class="p">;</span>
    <span class="o">/*</span> <span class="n">Receive</span> <span class="n">the</span> <span class="n">halo</span> <span class="n">data</span> <span class="o">*/</span>
    <span class="nb">int</span> <span class="n">source_rank</span> <span class="o">=</span> <span class="n">size</span><span class="o">-</span><span class="n">rank</span><span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="n">MPI_Recv</span><span class="p">(</span><span class="n">working_data_set</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="mi">8</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">source_rank</span><span class="p">,</span> <span class="n">send_up_tag</span><span class="p">,</span> <span class="n">comm</span><span class="p">,</span> <span class="n">MPI_STATUS_IGNORE</span><span class="p">);</span>
    <span class="n">MPI_Recv</span><span class="p">(</span><span class="n">working_data_set</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">8</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">source_rank</span><span class="p">,</span> <span class="n">send_down_tag</span><span class="p">,</span> <span class="n">comm</span><span class="p">,</span> <span class="n">MPI_STATUS_IGNORE</span><span class="p">);</span>

    <span class="o">/*</span> <span class="n">Send</span> <span class="n">the</span> <span class="n">border</span> <span class="n">data</span> <span class="o">*/</span>
    <span class="nb">int</span> <span class="n">destination_rank</span> <span class="o">=</span> <span class="n">size</span><span class="o">-</span><span class="n">rank</span><span class="o">-</span><span class="mi">1</span><span class="p">;</span>
    <span class="n">MPI_Ssend</span><span class="p">(</span><span class="n">working_data_set</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">8</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">destination_rank</span><span class="p">,</span> <span class="n">send_up_tag</span><span class="p">,</span> <span class="n">comm</span><span class="p">);</span>
    <span class="n">MPI_Ssend</span><span class="p">(</span><span class="n">working_data_set</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="mi">8</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">destination_rank</span><span class="p">,</span> <span class="n">send_down_tag</span><span class="p">,</span> <span class="n">comm</span><span class="p">);</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p>There are other approaches that work correctly. Is yours better
or worse than this one? Why?</p></li>
</ul>
</div>
<div class="admonition-ovelaping-communication-and-computation exercise important admonition" id="exercise-1">
<p class="admonition-title">Ovelaping communication and computation</p>
<p>You can find a scaffold for the code in the
<code class="docutils literal notranslate"><span class="pre">content/code/day-2/05_overlap</span></code> folder.  A working solution is in the
<code class="docutils literal notranslate"><span class="pre">solution</span></code> subfolder. Try to compile with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mpicc</span> <span class="o">-</span><span class="n">g</span> <span class="o">-</span><span class="n">Wall</span> <span class="o">-</span><span class="n">std</span><span class="o">=</span><span class="n">c11</span> <span class="n">non</span><span class="o">-</span><span class="n">blocking</span><span class="o">-</span><span class="n">communication</span><span class="o">-</span><span class="n">overlap</span><span class="o">.</span><span class="n">c</span> <span class="o">-</span><span class="n">o</span> <span class="n">non</span><span class="o">-</span><span class="n">blocking</span><span class="o">-</span><span class="n">communication</span><span class="o">-</span><span class="n">overlap</span>
</pre></div>
</div>
<ol class="arabic">
<li><p>When you have the code compiling, try to run with:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">mpiexec</span> <span class="o">-</span><span class="n">np</span> <span class="mi">2</span> <span class="o">./</span><span class="n">non</span><span class="o">-</span><span class="n">blocking</span><span class="o">-</span><span class="n">communication</span><span class="o">-</span><span class="n">overlap</span>
</pre></div>
</div>
</li>
<li><p>Try to fix the code so that local and non-local computations are overlapped between the the
send/recv  and wait calls.</p></li>
</ol>
</div>
<div class="admonition-solution solution important dropdown admonition" id="solution-1">
<p class="admonition-title">Solution</p>
<ul>
<li><p>One correct approach is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">MPI_Irecv</span><span class="p">(</span><span class="n">working_data_set</span><span class="p">[</span><span class="mi">5</span><span class="p">],</span> <span class="mi">8</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">source_rank</span><span class="p">,</span> <span class="n">send_up_tag</span><span class="p">,</span> <span class="n">comm</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">sent_from_source</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<span class="n">MPI_Irecv</span><span class="p">(</span><span class="n">working_data_set</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="mi">8</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">source_rank</span><span class="p">,</span> <span class="n">send_down_tag</span><span class="p">,</span> <span class="n">comm</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">sent_from_source</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>

<span class="o">/*</span> <span class="n">Prepare</span> <span class="n">to</span> <span class="n">send</span> <span class="n">the</span> <span class="n">border</span> <span class="n">data</span> <span class="o">*/</span>
<span class="nb">int</span> <span class="n">destination_rank</span> <span class="o">=</span> <span class="n">size</span><span class="o">-</span><span class="n">rank</span><span class="o">-</span><span class="mi">1</span><span class="p">;</span>
<span class="n">MPI_Request</span> <span class="n">sent_to_destination</span><span class="p">[</span><span class="mi">2</span><span class="p">];</span>
<span class="n">MPI_Isend</span><span class="p">(</span><span class="n">working_data_set</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="mi">8</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">destination_rank</span><span class="p">,</span> <span class="n">send_up_tag</span><span class="p">,</span> <span class="n">comm</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">sent_to_destination</span><span class="p">[</span><span class="mi">0</span><span class="p">]);</span>
<span class="n">MPI_Isend</span><span class="p">(</span><span class="n">working_data_set</span><span class="p">[</span><span class="mi">4</span><span class="p">],</span> <span class="mi">8</span><span class="p">,</span> <span class="n">MPI_INT</span><span class="p">,</span> <span class="n">destination_rank</span><span class="p">,</span> <span class="n">send_down_tag</span><span class="p">,</span> <span class="n">comm</span><span class="p">,</span> <span class="o">&amp;</span><span class="n">sent_to_destination</span><span class="p">[</span><span class="mi">1</span><span class="p">]);</span>

<span class="o">/*</span> <span class="n">Do</span> <span class="n">the</span> <span class="n">local</span> <span class="n">computation</span> <span class="o">*/</span>
<span class="n">compute_row</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span> <span class="n">working_data_set</span><span class="p">,</span> <span class="n">next_working_data_set</span><span class="p">);</span>
<span class="n">compute_row</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">working_data_set</span><span class="p">,</span> <span class="n">next_working_data_set</span><span class="p">);</span>

<span class="o">/*</span> <span class="n">Wait</span> <span class="k">for</span> <span class="n">the</span> <span class="n">receives</span> <span class="n">to</span> <span class="n">complete</span> <span class="o">*/</span>
<span class="n">MPI_Wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sent_from_source</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">MPI_STATUS_IGNORE</span><span class="p">);</span>
<span class="n">MPI_Wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sent_from_source</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">MPI_STATUS_IGNORE</span><span class="p">);</span>

<span class="o">/*</span> <span class="n">Do</span> <span class="n">the</span> <span class="n">non</span><span class="o">-</span><span class="n">local</span> <span class="n">computation</span> <span class="o">*/</span>
<span class="n">compute_row</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">working_data_set</span><span class="p">,</span> <span class="n">next_working_data_set</span><span class="p">);</span>
<span class="n">compute_row</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">working_data_set</span><span class="p">,</span> <span class="n">next_working_data_set</span><span class="p">);</span>

<span class="o">/*</span> <span class="n">Wait</span> <span class="k">for</span> <span class="n">the</span> <span class="n">sends</span> <span class="n">to</span> <span class="n">complete</span> <span class="o">*/</span>
<span class="n">MPI_Wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sent_to_destination</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">MPI_STATUS_IGNORE</span><span class="p">);</span>
<span class="n">MPI_Wait</span><span class="p">(</span><span class="o">&amp;</span><span class="n">sent_to_destination</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">MPI_STATUS_IGNORE</span><span class="p">);</span>
</pre></div>
</div>
</li>
</ul>
</div>
</section>
<section id="see-also">
<h2>See also<a class="headerlink" href="#see-also" title="Permalink to this heading"></a></h2>
<ul class="simple">
<li><p>Chapter 1 of the <strong>Using Advanced MPI</strong> book by William Gropp <em>et al.</em> shows
examples of using the functions described in this episode.
<span id="id1">[<a class="reference internal" href="../zbibliography/#id2" title="William Gropp, Torsten Hoefler, Rajeev Thakur, and Ewing Lusk. Using Advanced MPI: Modern Features of the Message-Passing Interface. Scientific and Engineering Computation. MIT Press, November 2014. ISBN 9780262527637. URL: https://mitpress.mit.edu/books/using-advanced-mpi.">GHTL14</a>]</span></p></li>
<li><p><a class="reference external" href="https://www.codingame.com/playgrounds/349/introduction-to-mpi/non-blocking-communications">Codin Game: non-blocking communications</a></p></li>
</ul>
<div class="admonition-keypoints keypoints admonition" id="keypoints-0">
<p class="admonition-title">Keypoints</p>
<ul class="simple">
<li><p>Non-blocking point-to-point communications can be used to avoid deadlocks from blocking communications.</p></li>
<li><p>Also, non-blocking messages can decrease idle times and allow for the possibility of interleaving
computation and communication.</p></li>
<li><p>Be aware of not modifying the buffer used by <a class="reference internal" href="../quick-reference/index.html#term-MPI_Isend"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Isend</code></span></a>/<a class="reference internal" href="../quick-reference/index.html#term-MPI_Irecv"><span class="xref std std-term"><code class="docutils literal notranslate">MPI_Irecv</code></span></a> prior to completion.</p></li>
</ul>
</div>
</section>
</section>


           </div>
          </div>
          <footer><div class="rst-footer-buttons" role="navigation" aria-label="Footer">
        <a href="../collective-communication-pt3/" class="btn btn-neutral float-left" title="Generalized forms of gather" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left" aria-hidden="true"></span> Previous</a>
        <a href="../non-blocking-communication-pt2/" class="btn btn-neutral float-right" title="Non-blocking collective communication" accesskey="n" rel="next">Next <span class="fa fa-arrow-circle-right" aria-hidden="true"></span></a>
    </div>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2020, EuroCC National Competence Centre Sweden.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>